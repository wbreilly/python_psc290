{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sms_scan_exit_survey.csv\",keep_default_na=False) #leave blanks as blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  dates take the place of subject labels\n",
    "### Phrasing of question was changed after first six participants, much messier individual sequence responses for those first subjects, so I can either spend a bunch of time trying to organize that, or ignore those subjects, or just ignore individual sequences and merge across questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>1. For each sequence, please characterize the strategies you used to remember the verbs.</th>\n",
       "      <th>2. Did you use verbal knowledge or experience (an event) to remember each sequence?</th>\n",
       "      <th>3. In general, while making your responses, did you think of a singular event that occurred once at a particular time and place?</th>\n",
       "      <th>4. In general, while making your responses, did you think of a summary or merging of many similar or related events?</th>\n",
       "      <th>5. In general, while making your responses, did you think of a continuous event that occurred over an  extended period of time lasting more than one day?</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017/07/26 2:14:42 PM MDT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes, I thought of a singular event that the wo...</td>\n",
       "      <td>I didn't try to think of any similar events th...</td>\n",
       "      <td>No, they were more like short segments sewed t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017/07/28 12:50:17 PM MDT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2/intact - no particular event\\n3/scrambled - ...</td>\n",
       "      <td>2/intact - yes very much, as this would be a c...</td>\n",
       "      <td>3/scrambled - no, this event in my head lasted...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017/08/02 10:58:33 AM MDT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2 scrambled no\\n3 random1 no\\n4 intact no\\n5 s...</td>\n",
       "      <td>2 scrambled yes\\n3 random1 no\\n4 intact no\\n5 ...</td>\n",
       "      <td>2 scrambled no\\n3 random1 yes\\n4 intact yes\\n5...</td>\n",
       "      <td>No problems.</td>\n",
       "      <td>I think that the problems I had were there on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017/08/24 2:48:51 PM MDT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>no for all</td>\n",
       "      <td>yes for 2, 5, 6, 7, 9, 12, 13, 15 and no for t...</td>\n",
       "      <td>yes for 3, 4, 16 (kind of) and no for the rest</td>\n",
       "      <td></td>\n",
       "      <td>2, intact --  I realized that it was a basic d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017/08/30 2:45:52 PM MDT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>intact - 2  - No   \\n\\nscramble - 3 -  Yes; I ...</td>\n",
       "      <td>intact - 2  -  Yes. I thought of my own experi...</td>\n",
       "      <td>intact - 2  -  No\\n\\nscramble - 3 -  No\\n\\nran...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Timestamp  \\\n",
       "0   2017/07/26 2:14:42 PM MDT   \n",
       "1  2017/07/28 12:50:17 PM MDT   \n",
       "2  2017/08/02 10:58:33 AM MDT   \n",
       "3   2017/08/24 2:48:51 PM MDT   \n",
       "4   2017/08/30 2:45:52 PM MDT   \n",
       "\n",
       "  1. For each sequence, please characterize the strategies you used to remember the verbs.  \\\n",
       "0                                                                                            \n",
       "1                                                                                            \n",
       "2                                                                                            \n",
       "3                                                                                            \n",
       "4                                                                                            \n",
       "\n",
       "  2. Did you use verbal knowledge or experience (an event) to remember each sequence?   \\\n",
       "0                                                                                        \n",
       "1                                                                                        \n",
       "2                                                                                        \n",
       "3                                                                                        \n",
       "4                                                                                        \n",
       "\n",
       "  3. In general, while making your responses, did you think of a singular event that occurred once at a particular time and place?  \\\n",
       "0  Yes, I thought of a singular event that the wo...                                                                                 \n",
       "1  2/intact - no particular event\\n3/scrambled - ...                                                                                 \n",
       "2  2 scrambled no\\n3 random1 no\\n4 intact no\\n5 s...                                                                                 \n",
       "3                                         no for all                                                                                 \n",
       "4  intact - 2  - No   \\n\\nscramble - 3 -  Yes; I ...                                                                                 \n",
       "\n",
       "  4. In general, while making your responses, did you think of a summary or merging of many similar or related events?  \\\n",
       "0  I didn't try to think of any similar events th...                                                                     \n",
       "1  2/intact - yes very much, as this would be a c...                                                                     \n",
       "2  2 scrambled yes\\n3 random1 no\\n4 intact no\\n5 ...                                                                     \n",
       "3  yes for 2, 5, 6, 7, 9, 12, 13, 15 and no for t...                                                                     \n",
       "4  intact - 2  -  Yes. I thought of my own experi...                                                                     \n",
       "\n",
       "  5. In general, while making your responses, did you think of a continuous event that occurred over an  extended period of time lasting more than one day?   \\\n",
       "0  No, they were more like short segments sewed t...                                                                                                           \n",
       "1  3/scrambled - no, this event in my head lasted...                                                                                                           \n",
       "2  2 scrambled no\\n3 random1 yes\\n4 intact yes\\n5...                                                                                                           \n",
       "3     yes for 3, 4, 16 (kind of) and no for the rest                                                                                                           \n",
       "4  intact - 2  -  No\\n\\nscramble - 3 -  No\\n\\nran...                                                                                                           \n",
       "\n",
       "      Unnamed: 6                                         Unnamed: 7  \n",
       "0                                                                    \n",
       "1             No                                                 No  \n",
       "2  No problems.   I think that the problems I had were there on ...  \n",
       "3                 2, intact --  I realized that it was a basic d...  \n",
       "4             No                                                 No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.columns = ['Subject','Q1','Q2','Q3','Q4','Q5','Q6','Q7']\n",
    "# merge across questions, so all responses from each subject will be in one column\n",
    "df['merged'] =  df.iloc[:, 1:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for between subject overall differences by building a tf-idf model from all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize merged responses\n",
    "df['tok_merged'] = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in df['merged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean # of tokens: 18467\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD/CAYAAAD4xAEfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt77iFNdljNEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d9831d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot number of tokens by subject\n",
    "num_toks = df.tok_merged.apply(len)\n",
    "print('Mean # of tokens:' ,np.sum(num_toks))\n",
    "num_toks.plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary\n",
    "dictionary = gensim.corpora.Dictionary(df['tok_merged'])\n",
    "# see how many words in the dictionary\n",
    "len(dictionary)\n",
    "# I would have thought there would be more unique words... I guess that's good? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=24, num_nnz=6034)\n"
     ]
    }
   ],
   "source": [
    "# create a corpus \n",
    "corpus = [dictionary.doc2bow(x) for x in df['tok_merged']]\n",
    "# creat tf-idf model of the corpus\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 24 documents in 0 shards (stored under /Users/WBR/walter/python_psc290/hw)\n"
     ]
    }
   ],
   "source": [
    "# creat similarlity object with gensim\n",
    "# get path\n",
    "cwd = os.getcwd()\n",
    "sims = gensim.similarities.Similarity(cwd,tf_idf[corpus],\n",
    "                                      num_features=len(dictionary))\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now create a query from one sub's responses by first bag of words-ing\n",
    "query_doc_bow = dictionary.doc2bow(df['tok_merged'][1])\n",
    "# then index tf_idf weights\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04068984, 1.0000002 , 0.15550756, 0.02335448, 0.11137828,\n",
       "       0.05439073, 0.06243492, 0.05343318, 0.16747609, 0.14928679,\n",
       "       0.06551225, 0.03037687, 0.00508134, 0.04148054, 0.05474997,\n",
       "       0.0772889 , 0.02482655, 0.02682976, 0.034339  , 0.02597768,\n",
       "       0.06060001, 0.02821321, 0.03432068, 0.05014485], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Similarity.similarity_by_id of <gensim.similarities.docsim.Similarity object at 0x1a1eac0b00>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.similarity_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.999999  , 0.04068984, 0.0532045 , 0.0438494 , 0.1888521 ,\n",
       "       0.07426773, 0.09896921, 0.13354322, 0.0614248 , 0.07154027,\n",
       "       0.15344808, 0.12431833, 0.07758443, 0.251034  , 0.06363554,\n",
       "       0.1644273 , 0.04082078, 0.07279146, 0.04689367, 0.0554514 ,\n",
       "       0.11407172, 0.08240511, 0.08692756, 0.0948897 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sims)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-12021b914650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df=1)\n",
    "tfidf = vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
